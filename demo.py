import time
import torch
import streamlit as st
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# --------------------------------------------------
# 1. Paths to fine‚Äëtuned models (folder checkpoints)
# --------------------------------------------------
SENTIMENT_MODEL_DIR = "models/sentiment_analysis"      # contains config.json + model.safetensors
TOPIC_MODEL_DIR     = "models/topic_classification"    # same structure for topic classifier

# --------------------------------------------------
# 2. Device setup
# --------------------------------------------------
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# --------------------------------------------------
# 3. Load tokenizers & models
#    ‚îÄ‚îÄ Fix for meta‚Äëtensor error: load on CPU first, then .to(DEVICE) if CUDA
# --------------------------------------------------
# Sentiment (binary)
tokenizer_sentiment = AutoTokenizer.from_pretrained(SENTIMENT_MODEL_DIR)
model_sentiment = AutoModelForSequenceClassification.from_pretrained(
    SENTIMENT_MODEL_DIR,
    torch_dtype=torch.float32,   # ensure real tensors
    device_map=None              # load fully on CPU
)
if DEVICE.type == "cuda":
    model_sentiment.to(DEVICE)
model_sentiment.eval()

# Topic (10 classes)
tokenizer_topic = AutoTokenizer.from_pretrained(TOPIC_MODEL_DIR)
model_topic = AutoModelForSequenceClassification.from_pretrained(
    TOPIC_MODEL_DIR,
    torch_dtype=torch.float32,
    device_map=None
)
if DEVICE.type == "cuda":
    model_topic.to(DEVICE)
model_topic.eval()

# --------------------------------------------------
# 4. Helper functions
# --------------------------------------------------

def _preprocess(text: str, tokenizer, max_len: int = 512):
    """Tokenise a single text and return (input_ids, attention_mask) tensors."""
    enc = tokenizer(text,
                    add_special_tokens=True,
                    max_length=max_len,
                    padding="max_length",
                    truncation=True,
                    return_tensors="pt")
    return enc["input_ids"].to(DEVICE), enc["attention_mask"].to(DEVICE)

# --------------------------------------------------
# 5. Sentiment prediction
# --------------------------------------------------

def predict_sentiment(text: str):
    if not text.strip():
        return None
    time.sleep(1)
    input_ids, attn_mask = _preprocess(text, tokenizer_sentiment, max_len=256)
    with torch.no_grad():
        logits = model_sentiment(input_ids=input_ids, attention_mask=attn_mask).logits
        probs  = torch.softmax(logits, dim=1)
        pred   = torch.argmax(probs, dim=1).item()
        conf   = probs[0, pred].item()
    label = "T√≠ch c·ª±c" if pred == 1 else "Ti√™u c·ª±c"
    return label, conf

# --------------------------------------------------
# 6. Topic prediction
# --------------------------------------------------
CLASS_LABELS = [
    "Society & Culture",
    "Science & Mathematics",
    "Health",
    "Education & Reference",
    "Computers & Internet",
    "Sports",
    "Business & Finance",
    "Entertainment & Music",
    "Family & Relationships",
    "Politics & Government",
]

def predict_topic(text: str):
    if not text.strip():
        return None
    time.sleep(1)
    input_ids, attn_mask = _preprocess(text, tokenizer_topic, max_len=256)
    with torch.no_grad():
        logits = model_topic(input_ids=input_ids, attention_mask=attn_mask).logits
        probs  = torch.softmax(logits, dim=1)
        pred   = torch.argmax(probs, dim=1).item()
        conf   = probs[0, pred].item()
    return CLASS_LABELS[pred], conf

# --------------------------------------------------
# 7. Streamlit UI
# --------------------------------------------------

st.set_page_config(page_title="H·ªá th·ªëng D·ª± ƒëo√°n AI", layout="centered")

st.title("üß† H·ªá th·ªëng D·ª± ƒëo√°n AI")
st.subheader("üîç Ph√¢n t√≠ch c·∫£m x√∫c & ph√¢n lo·∫°i ch·ªß ƒë·ªÅ")

tab_sentiment, tab_topic = st.tabs(["üì¶ C·∫£m x√∫c", "üè∑Ô∏è Ch·ªß ƒë·ªÅ"])

with tab_sentiment:
    st.markdown("Nh·∫≠p vƒÉn b·∫£n m√† b·∫°n mu·ªën ph√¢n t√≠ch c·∫£m x√∫c (T√≠ch c·ª±c / Ti√™u c·ª±c).")
    txt_inp = st.text_area("‚úçÔ∏è Nh·∫≠p vƒÉn b·∫£n", height=150, key="sentiment_input")
    if st.button("üìä Ph√¢n t√≠ch C·∫£m x√∫c"):
        with st.spinner("ƒêang ph√¢n t√≠ch..."):
            result = predict_sentiment(txt_inp)
        if result:
            label, conf = result
            st.success(f"**K·∫øt qu·∫£:** {label}")
            st.info(f"ƒê·ªô tin c·∫≠y: {conf*100:.1f}%")

with tab_topic:
    st.markdown("Nh·∫≠p vƒÉn b·∫£n m√† b·∫°n mu·ªën ph√¢n lo·∫°i ch·ªß ƒë·ªÅ (C√¥ng ngh·ªá, S·ª©c kh·ªèe, ...).")
    txt_inp = st.text_area("‚úçÔ∏è Nh·∫≠p vƒÉn b·∫£n", height=150, key="topic_input")
    if st.button("üìö Ph√¢n lo·∫°i Ch·ªß ƒë·ªÅ"):
        with st.spinner("ƒêang ph√¢n lo·∫°i..."):
            result = predict_topic(txt_inp)
        if result:
            topic, conf = result
            st.success(f"**Ch·ªß ƒë·ªÅ:** {topic}")
            st.info(f"ƒê·ªô tin c·∫≠y: {conf*100:.1f}%")

st.markdown("---")
st.caption("üí° ƒê√¢y l√† b·∫£n demo c·ªßa ·ª©ng d·ª•ng.")
