import streamlit as st
import torch
import time
from transformers import AutoTokenizer, AutoModelForSequenceClassification, BertForSequenceClassification

# ÄÆ°á»ng dáº«n Ä‘áº¿n mÃ´ hÃ¬nh fine-tuned
model_path_sentiment = "model_sentiment_analysis"
model_path_topic = "model_topic classification/best_model.bin"

# Tá»± Ä‘á»™ng chá»n thiáº¿t bá»‹ GPU náº¿u cÃ³, ngÆ°á»£c láº¡i dÃ¹ng CPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Load tokenizer vÃ  config
tokenizer_sentiment = AutoTokenizer.from_pretrained(model_path_sentiment)
tokenizer_topic = AutoTokenizer.from_pretrained("bert-base-uncased")

# Load mÃ´ hÃ¬nh tá»« 
model_sentiment = AutoModelForSequenceClassification.from_pretrained(model_path_sentiment)
model_topic = BertForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=10)
model_topic.load_state_dict(torch.load(model_path_topic, map_location=torch.device('cpu'), weights_only=False))

model_sentiment.eval()
model_topic.eval()

# Dá»± Ä‘oÃ¡n cáº£m xÃºc Amazon
def predict_amazon_sentiment(text):
    if not text.strip():
        return None

    time.sleep(2)  # Giáº£ láº­p delay API

    def preprocess_text(text, tokenizer, max_len=512):
        encoding = tokenizer.encode_plus(
            text,
            add_special_tokens=True,
            max_length=max_len,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        )
        return encoding['input_ids'], encoding['attention_mask']
    
    input_ids, attention_mask = preprocess_text(text, tokenizer_sentiment)

    # ÄÆ°a input vá» Ä‘Ãºng device
    input_ids = input_ids.to(device)
    attention_mask = attention_mask.to(device) 
       
    with torch.no_grad():
        outputs = model_sentiment(input_ids=input_ids, attention_mask=attention_mask)
        probs = torch.nn.functional.softmax(outputs.logits, dim=1)
        predicted_class = torch.argmax(probs, dim=1).item()
        confidence = probs[0][predicted_class].item()

    sentiment = "TiÃªu cá»±c"
    if predicted_class == 1:
        sentiment = "TÃ­ch cá»±c"

    return sentiment, confidence


# Dá»± Ä‘oÃ¡n chá»§ Ä‘á» Yahoo
def predict_yahoo_topic(text):
    if not text.strip():
        return None

    time.sleep(2)  # Giáº£ láº­p delay API

    def preprocess_text(text, tokenizer, max_len=512):
        encoding = tokenizer.encode_plus(
            text,
            add_special_tokens=True,
            max_length=max_len,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        )
        return encoding['input_ids'], encoding['attention_mask']
    
    input_ids, attention_mask = preprocess_text(text, tokenizer_sentiment)
    
    # ÄÆ°a input vá» Ä‘Ãºng device
    input_ids = input_ids.to(torch.device('cpu'))
    attention_mask = attention_mask.to(torch.device('cpu'))

       
    with torch.no_grad():
        outputs = model_sentiment(input_ids=input_ids, attention_mask=attention_mask)
        probs = torch.nn.functional.softmax(outputs.logits, dim=1)
        predicted_class = torch.argmax(probs, dim=1).item()
        confidence = probs[0][predicted_class].item()

    best_topic = ""

    class_labels = [
    "Society & Culture",
    "Science & Mathematics",
    "Health",
    "Education & Reference",
    "Computers & Internet",
    "Sports",
    "Business & Finance",
    "Entertainment & Music",
    "Family & Relationships",
    "Politics & Government"
    ]   

    best_topic = class_labels[predicted_class]

    return best_topic, confidence

# Giao diá»‡n
st.set_page_config(page_title="Há»‡ thá»‘ng Dá»± Ä‘oÃ¡n AI", layout="centered")

st.title("ğŸ§  Há»‡ thá»‘ng Dá»± Ä‘oÃ¡n AI")
st.subheader("ğŸ” PhÃ¢n tÃ­ch cáº£m xÃºc & phÃ¢n loáº¡i chá»§ Ä‘á»")

tab1, tab2 = st.tabs(["ğŸ“¦ Cáº£m xÃºc", "ğŸ·ï¸ Chá»§ Ä‘á»"])

with tab1:
    st.markdown("Nháº­p vÄƒn báº£n mÃ  báº¡n muá»‘n phÃ¢n tÃ­ch cáº£m xÃºc (TÃ­ch cá»±c / Trung tÃ­nh).")
    amazon_input = st.text_area("âœï¸ Nháº­p vÄƒn báº£n", height=150, key="amazon_input")

    if st.button("ğŸ“Š PhÃ¢n tÃ­ch Cáº£m xÃºc", key="amazon"):
        with st.spinner("Äang phÃ¢n tÃ­ch..."):
            result = predict_amazon_sentiment(amazon_input)
        if result:
            sentiment, confidence = result
            st.success(f"**Káº¿t quáº£:** {sentiment}")
            st.info(f"Äá»™ tin cáº­y: {confidence*100:.1f}%")

with tab2:
    st.markdown("Nháº­p vÄƒn báº£n mÃ  báº¡n muá»‘n phÃ¢n loáº¡i chá»§ Ä‘á» (CÃ´ng nghá»‡, Sá»©c khá»e, ...).")
    yahoo_input = st.text_area("âœï¸ Nháº­p vÄƒn báº£n", height=150, key="yahoo_input")

    if st.button("ğŸ“š PhÃ¢n loáº¡i Chá»§ Ä‘á»", key="yahoo"):
        with st.spinner("Äang phÃ¢n loáº¡i..."):
            result = predict_yahoo_topic(yahoo_input)
        if result:
            topic, confidence = result
            st.success(f"**Chá»§ Ä‘á»:** {topic}")
            st.info(f"Äá»™ tin cáº­y: {confidence*100:.1f}%")

st.markdown("---")
st.caption("ğŸ’¡ ÄÃ¢y lÃ  báº£n demo cá»§a á»©ng dá»¥ng.")

 